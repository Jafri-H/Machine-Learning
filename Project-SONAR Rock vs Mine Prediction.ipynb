{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mYSLvRgB3Sel"},"source":["## Importing Dependencies  \n","- **numpy** is used for numerical computations.  \n","- **pandas** is used for handling tabular data.  \n","- **train_test_split** helps in splitting data for training and testing.  \n","- **LogisticRegression** is the model used for classification.  \n","- **accuracy_score** helps evaluate model performance.\n"]},{"cell_type":"code","metadata":{"id":"cbE3ZjDb23el","executionInfo":{"status":"ok","timestamp":1740277458629,"user_tz":420,"elapsed":2166,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fCLGacZR4UZx"},"source":["## Loading the Dataset\n","- The dataset is loaded using **pd.read_csv()**, which is a function in pandas that reads CSV (Comma-Separated Values) files and loads them into a DataFrame.  \n","- **header=None** is used because the dataset does not have predefined column names. Without this, pandas would assume the first row as column names. By setting **header=None**, all rows are treated as data, and pandas assigns default numerical column indices starting from 0.  "]},{"cell_type":"code","metadata":{"id":"7ymxgj2i3RwO","colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"status":"error","timestamp":1740277458914,"user_tz":420,"elapsed":287,"user":{"displayName":"Jafri","userId":"05252005366316497473"}},"outputId":"100bae10-2f25-4b1c-f4cb-c70d7b2c66c8"},"source":["sonar_data = pd.read_csv('/content/sonar data.csv', header=None)"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/sonar data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-3b123a2a90fd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msonar_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sonar data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sonar data.csv'"]}]},{"cell_type":"markdown","source":["## Displaying First Few Rows\n","- **head()** shows the first 5 rows of the dataset for inspection. It helps in quickly understanding the structure and contents of the dataset.  "],"metadata":{"id":"4wRuwrvUsPus"}},{"cell_type":"code","metadata":{"id":"I5iWxSnM42fl","executionInfo":{"status":"aborted","timestamp":1740277458976,"user_tz":420,"elapsed":2,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["sonar_data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Understanding Dataset Shape\n","- **shape** returns the number of rows and columns in the dataset. It helps in understanding the dataset's dimensions.  \n"],"metadata":{"id":"WSU9kvugsp0K"}},{"cell_type":"code","metadata":{"id":"WN_FI_eN48V_","executionInfo":{"status":"aborted","timestamp":1740277458980,"user_tz":420,"elapsed":1,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["sonar_data.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Statistical Summary  \n","- **describe()** provides statistical insights such as mean, standard deviation, minimum, maximum, and quartile values for numerical columns in the dataset. It helps in understanding the distribution of data.  \n"],"metadata":{"id":"F0infcMCs7B4"}},{"cell_type":"code","metadata":{"id":"q6A1r9J-5aOJ","executionInfo":{"status":"aborted","timestamp":1740277459023,"user_tz":420,"elapsed":41,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["sonar_data.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Checking Class Distribution\n","- The dataset has labels in the **60th column**.  \n","- **value_counts()** shows the count of each class **Rock-(R)** or **Mine-(M)**, helping to understand the distribution of target labels.  \n"],"metadata":{"id":"ZbDwfHXUtLsa"}},{"cell_type":"code","metadata":{"id":"XFlxfDyk5o00","executionInfo":{"status":"aborted","timestamp":1740277459027,"user_tz":420,"elapsed":16,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["sonar_data[60].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uis1XlFs6M09","executionInfo":{"status":"aborted","timestamp":1740277459030,"user_tz":420,"elapsed":17,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["sonar_data.groupby(60).mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **X**: The features (independent variables) of the dataset, obtained by dropping the column with index **60** from **sonar_data**.\n","- **Y**: The target (dependent variable) of the dataset, which corresponds to the column with index **60** from **sonar_data**.\n","- **drop(columns = 60, axis = 1)**: Removes the column at index **60** (which is the target) from the dataset to create the feature set **X**.\n","- **sonar_data[60]**: Selects the column at index **60** from **sonar_data** as the target variable **Y**.\n"],"metadata":{"id":"cRuQHTlhvYld"}},{"cell_type":"code","metadata":{"id":"qRShuFc46jLd","executionInfo":{"status":"aborted","timestamp":1740277459032,"user_tz":420,"elapsed":18,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["# separating data and Labels\n","X = sonar_data.drop(columns=60, axis=1)\n","Y = sonar_data[60]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **print(X)**: This will display the feature set **X**, which contains all the input variables of the dataset except for the column at index **60** (the target variable).\n","- **print(Y)**: This will display the target variable **Y**, which contains the values from the column at index **60** of the **sonar_data**.\n"],"metadata":{"id":"Xqtn2n4_wKJt"}},{"cell_type":"code","metadata":{"id":"mkRRrxIe7D7l","executionInfo":{"status":"aborted","timestamp":1740277459035,"user_tz":420,"elapsed":19,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["print(X)\n","print(Y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j912DrKe7L03"},"source":["## Splitting Data into Train & Test\n","- **train_test_split()** divides the dataset into training and testing sets, ensuring the model is evaluated on unseen data.  \n","- **X**: The input features (independent variables) of the dataset.\n","- **Y**: The target labels (dependent variable) of the dataset.\n","- **test_size=0.1**: This specifies that **10%** of the dataset will be used for testing, while **90%** will be used for training.\n","- **stratify=Y**: Ensures the class distribution in the target variable `Y` is preserved in both the training and testing sets. This is useful for handling imbalanced datasets.\n","- **random_state=1**: This ensures the split is reproducible. By setting a random seed, you ensure that the split will be the same every time the code is run with this value.\n","\n"]},{"cell_type":"code","metadata":{"id":"bTnEFld87GIr","executionInfo":{"status":"aborted","timestamp":1740277459038,"user_tz":420,"elapsed":21,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, stratify=Y, random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Printing the shapes (dimensions) of the following arrays:<br>\n","**print(X.shape, X_train.shape, X_test.shape)**:\n","- **X.shape**: The shape of the original feature set **X**, showing the number of samples (rows) and features (columns).\n","- **X_train.shape**: The shape of the training feature set **X_train**, showing how many samples and features are used for training.\n","- **X_test.shape**: The shape of the testing feature set **X_test**, showing how many samples and features are used for testing.\n"],"metadata":{"id":"YTMcvY4twiP_"}},{"cell_type":"code","metadata":{"id":"ww4D1Ps379_h","executionInfo":{"status":"aborted","timestamp":1740277459041,"user_tz":420,"elapsed":22,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["print(X.shape, X_train.shape, X_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **print(X_train)**: This will display the feature set for training **(`X_train`)**, which contains the input variables used to train the model.\n","- **print(Y_train)**: This will display the target variable for training **(`Y_train`)**, which contains the labels or outputs corresponding to the training data.\n"],"metadata":{"id":"tRsofCctxNRQ"}},{"cell_type":"code","metadata":{"id":"KBvcm4eR8enA","executionInfo":{"status":"aborted","timestamp":1740277459044,"user_tz":420,"elapsed":24,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["print(X_train)\n","print(Y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training the Logistic Regression Model\n","\n","- The process of training a machine learning model involves using the **fit()** method to adjust the model's parameters based on the training data.\n","  \n","- **LogisticRegression()**: This is a classification algorithm from **sklearn.linear_model**, used to predict binary or multi-class outcomes based on input features.\n","\n","- **fit() method**: The **fit()** method is used to train the logistic regression model on the provided training data.\n","- It takes two arguments: the feature set **(X_train)** and the target variable **(Y_train)**, and it learns the relationship between them.\n","\n"],"metadata":{"id":"sEv8xV6Txn01"}},{"cell_type":"code","metadata":{"id":"UoM3FhQS8FAw","executionInfo":{"status":"aborted","timestamp":1740277459046,"user_tz":420,"elapsed":24,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["model = LogisticRegression()\n","model.fit(X_train, Y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"585vgP7b8vBn"},"source":["## Evaluating Model Performance\n","- **X_train_prediction = model.predict(X_train)**: This line uses the trained logistic regression model to predict the labels (target values) for the training feature set **X_train**. The predicted values are stored in **X_train_prediction**.\n","\n","- **training_data_accuracy = accuracy_score(X_train_prediction, Y_train)**: This calculates the accuracy of the model on the training data by comparing the predicted labels **(X_train_prediction)** with the actual labels **(Y_train)**. The **accuracy_score** function from **sklearn.metrics** returns the proportion of correct predictions, which is stored in **training_data_accuracy**.\n"]},{"cell_type":"code","metadata":{"id":"kCBykEtO8pLi","executionInfo":{"status":"aborted","timestamp":1740277459048,"user_tz":420,"elapsed":2648,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["X_train_prediction = model.predict(X_train)\n","training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"50Wqy2Rc9nL1","executionInfo":{"status":"aborted","timestamp":1740277459049,"user_tz":420,"elapsed":2645,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["print('Accuracy on training data : ', training_data_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCUZ6MuR9tOV","executionInfo":{"status":"aborted","timestamp":1740277459056,"user_tz":420,"elapsed":4,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["#accuracy on test data\n","X_test_prediction = model.predict(X_test)\n","test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"04AsqCrz99vU","executionInfo":{"status":"aborted","timestamp":1740277459058,"user_tz":420,"elapsed":5,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["print('Accuracy on test data : ', test_data_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RKrIzmr8-K9s"},"source":["Making a Predictive System"]},{"cell_type":"code","metadata":{"id":"NMp-UfOd-B7B","executionInfo":{"status":"aborted","timestamp":1740277459060,"user_tz":420,"elapsed":6,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":["input_data = (0.0307,0.0523,0.0653,0.0521,0.0611,0.0577,0.0665,0.0664,0.1460,0.2792,0.3877,0.4992,0.4981,0.4972,0.5607,0.7339,0.8230,0.9173,0.9975,0.9911,0.8240,0.6498,0.5980,0.4862,0.3150,0.1543,0.0989,0.0284,0.1008,0.2636,0.2694,0.2930,0.2925,0.3998,0.3660,0.3172,0.4609,0.4374,0.1820,0.3376,0.6202,0.4448,0.1863,0.1420,0.0589,0.0576,0.0672,0.0269,0.0245,0.0190,0.0063,0.0321,0.0189,0.0137,0.0277,0.0152,0.0052,0.0121,0.0124,0.0055)\n","\n","# changing the input_data to a numpy array\n","input_data_as_numpy_array = np.asarray(input_data)\n","\n","# reshape the np array as we are predicting for one instance\n","input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n","\n","prediction = model.predict(input_data_reshaped)\n","print(prediction)\n","\n","if (prediction[0]=='R'):\n","  print('The object is a Rock')\n","else:\n","  print('The object is a mine')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tcg9Er11_TSv","executionInfo":{"status":"aborted","timestamp":1740277459062,"user_tz":420,"elapsed":7,"user":{"displayName":"Jafri","userId":"05252005366316497473"}}},"source":[],"execution_count":null,"outputs":[]}]}